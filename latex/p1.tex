Conversations are a frequent form of everyday social interaction and are characterized by rapid exchange of messages between the conversants.
The turn exchange system in human conversation is universal in nature and crosses culture, age and language \cite{levinson2016turn}. According to the
seminal work by Sack et al. \cite{sacks1974simplest}, a single speaker controls the conversation floor the majority of time in a conversation, conversants takes turns, and the gap and overlap between turns is kept to a minimum. These attributes apply regardless of turn length (from a single word to a full sentence) and conversation length.

In this work we are interested in the point of possible transition between speakers. To keep the gaps between turns minimal while supporting speaker change, the listener
must predict a possible turn transition before the end of the speaker's utterance. Two dominating approaches tried to explain the mechanisms by which
the conversation floor is allocated. Duncan \cite{duncan1972some} suggested that the speaker signals the listener about an upcoming turn transition by using a combination of one or more signals.
Another approach suggested by \cite{sacks1974simplest} defines the turn allocation process in terms of a set of local rules that are operated at possible turn transition points.
Both approaches (signaling and turn allocation rules) are based on phenomena that occur in the last few utterances (for example, the syntactic construct of the turn or the use of an adjutancy pair). This work investigates whether using features that were computed over all past turns can help to improve the predictability of turn transition.

Spoken dialogue systems (SDS) are computer systems that support a conversional speech-based user interface. Users engage in a conversation with the computer to
perform a task (for example, information seeking) by using their natural apparatus, the voice. Hence, to be effective and user friendly, an SDS should also adhere to the system of turn exchange.

Early SDS systems did not contain a turn management component and instead used a fixed timeout to detect the end of a user turn. Using a simple timeout led to barge-in situations, in which the system prematurely started to speak during the user's turn. Decreasing the barge-ins by increasing the timeout caused large gaps between turns, where the user waited for the system to speak.
To improve this situation, newer SDS systems are incorporating recent findings in human-human conversation in their prediction models. For example, features from the latest utterance are used to predict turn transition. Prediction in human-human conversation is based on syntactic \cite{sacks1974simplest,de2006projecting}, prosodic  \cite{ford1996interactional,stolcke2002speaker,ferrer2003prosody}, pragmatic cues  \cite{ford2001intersection}.
% introducing current research

While local features of the latest utterance form an important input for prediction, this thesis postulates that speakers might also use summary features computed over many turns. The summary features form a conversational image of the speaker and contain features that represent the speaker's average behavior over many turns. For example, average turn length measures the length in both time and words of each converstants turn up to this turn. Hence, if the length of the current speaker's turn is more than its average turn length, it is more likely that a turn ending will occur.






