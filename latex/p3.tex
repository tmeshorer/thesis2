To test the effectiveness of the summary features, we used the NXT version of the Switchboard corpus \cite{calhoun2010nxt,Godfrey-etal92:icassp} to train random forest models \cite{scikit-learn}. First we performed data preprocessing in order to merge turn, dialog act and single word information into a single data set. Next, we trained baseline models using local features: current and previous dialog acts. We also trained a model on the summary features as well as a model that includes both the local and the summary features. To measure the predictive power of the different models we use standard model metrics: F1, precision, recall and area under the curve (AUC)

